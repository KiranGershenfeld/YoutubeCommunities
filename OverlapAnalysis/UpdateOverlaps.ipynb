{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Channel overlaps are only calculated in one direction. \n",
    "#If a single channel and all of their connections are required, that can be obtained using this notebook. \n",
    "\n",
    "import boto3\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "overlap_bucket = 'youtube-overlaps'\n",
    "commenter_bucket = 'youtube-commenters'\n",
    "\n",
    "commenter_file_name = \"\"\n",
    "overlap_file_name = \"\"\n",
    "\n",
    "new_file_name = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_all_files_s3(bucket):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3_bucket = s3.Bucket(bucket)\n",
    "    files = []\n",
    "    for obj in s3_bucket.objects.all():\n",
    "        files.append(obj.key)\n",
    "    return files\n",
    "\n",
    "def load_pkl_obj_s3(file_name, bucket):\n",
    "    try:\n",
    "        s3 = boto3.resource('s3')\n",
    "        obj = pkl.loads(s3.Bucket(bucket).Object(file_name).get()['Body'].read())\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "        return load_pkl_obj_s3(file_name, bucket)\n",
    "        \n",
    "    return obj\n",
    "\n",
    "def dump_pkl_obj_s3(obj, file_name, bucket):\n",
    "    s3 = boto3.resource('s3')\n",
    "    pickle_obj = pkl.dumps(obj)\n",
    "    response = s3.Object(bucket, file_name).put(Body=pickle_obj)\n",
    "    return response['ResponseMetadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_overlaps_for_channel(channel_dict, channel_old_overlaps, bucket):\n",
    "    primary_channel = list(channel_dict.keys())[0]\n",
    "    primary_channel_commenter_set = set(channel_dict[primary_channel])\n",
    "    \n",
    "    utility_files = ['ChannelIdMap.pkl', 'CurrentChannel.pkl', 'YoutubeUsernames.pkl']\n",
    "    commenter_files = [file for file in see_all_files_s3(bucket) if file not in utility_files]\n",
    "    channel_file_dict = {}\n",
    "    for file_name in commenter_files:\n",
    "        prefix_len = 9\n",
    "        suffix_len = 17\n",
    "        channel_name = file_name[prefix_len:-suffix_len]\n",
    "        if(channel_name not in channel_old_overlaps[primary_channel]):\n",
    "            channel_file_dict[channel_name] = file_name\n",
    "\n",
    "    len(channel_file_dict)\n",
    "\n",
    "    for comparison_channel, comparison_file in channel_file_dict.items():\n",
    "        print(comparison_channel)\n",
    "\n",
    "        comparison_channel_commenter_dict = load_pkl_obj_s3(comparison_file, bucket)\n",
    "\n",
    "        shared_commenters = primary_channel_commenter_set & comparison_channel_commenter_dict[comparison_channel]\n",
    "        shared_commenter_count = len(shared_commenters)\n",
    "        channel_old_overlaps[primary_channel][comparison_channel] = shared_commenter_count\n",
    "    \n",
    "    \n",
    "    return channel_old_overlaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_dict = load_pkl_obj_s3(commenter_file_name, commenter_bucket)\n",
    "channel_old_overlaps = load_pkl_obj_s3(overlap_file_name, overlap_bucket)\n",
    "\n",
    "new_overlap_dict = calculate_new_overlaps_for_channel(channel_dict, channel_old_overlaps, commenter_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RequestId': '5VZ63F0J1NVYC3CE',\n",
       " 'HostId': 'Y0Z8YIQQykxek/t1/+iE1vxSgsODehUmAn6ObJesuD4jUmvQcE2BCwy8Z6fVC87cME8Edmn3eh8=',\n",
       " 'HTTPStatusCode': 200,\n",
       " 'HTTPHeaders': {'x-amz-id-2': 'Y0Z8YIQQykxek/t1/+iE1vxSgsODehUmAn6ObJesuD4jUmvQcE2BCwy8Z6fVC87cME8Edmn3eh8=',\n",
       "  'x-amz-request-id': '5VZ63F0J1NVYC3CE',\n",
       "  'date': 'Tue, 14 Dec 2021 22:34:32 GMT',\n",
       "  'etag': '\"0fdd80889d17bed6756fb2fff18e740d\"',\n",
       "  'server': 'AmazonS3',\n",
       "  'content-length': '0'},\n",
       " 'RetryAttempts': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success = dump_pkl_obj_s3(new_overlap_dict, new_file_name, overlap_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5696\n"
     ]
    }
   ],
   "source": [
    "#Verification\n",
    "channel_dict = load_pkl_obj_s3(new_file_name, overlap_bucket)\n",
    "print(len(channel_dict[list(channel_dict.keys())[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b2e88619c1c483adf9efb6ba1294707a7d17938092954dcbc7e3af579c2f9f0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
